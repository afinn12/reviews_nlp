# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sYf0IK8w2hDaRwkgJdMJGTN11_ClUbeS
"""

import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}, Number of GPUs: {torch.cuda.device_count()}")

nlp = spacy.load("en_core_web_sm")

category_attributes = {
    "Books": {
        "plot": ["plot", "story", "narrative"],
        "writing style": ["writing", "style", "prose"],
        "genre": ["genre", "category", "type"]
    },
    "Apparel": {
        "comfort": ["comfort", "comfortable", "cozy"],
        "material": ["material", "fabric", "quality"],
        "fit": ["fit", "size", "fitting"],
        "style": ["style", "design", "look"]
    },
    "Electronics": {
        "performance": ["performance", "speed", "efficiency"],
        "battery life": ["battery", "battery life", "power"],
        "ease of use": ["easy", "user-friendly", "intuitive"]
    },
    "Automotive": {
        "performance": ["performance", "speed", "efficiency"],
        "durability": ["durable", "last", "longevity"],
        "ease of installation": ["install", "setup", "assembly"]
    },
    "Baby": {
        "safety": ["safe", "safety", "secure"],
        "comfort": ["comfort", "comfortable", "cozy"],
        "durability": ["durable", "last", "longevity"]
    },
    "Beauty": {
        "texture": ["texture", "feel", "smooth"],
        "scent": ["scent", "smell", "fragrance"],
        "effectiveness": ["effective", "works", "results"]
    },
    "Camera": {
        "image quality": ["image", "picture", "resolution"],
        "ease of use": ["easy", "user-friendly", "intuitive"],
        "durability": ["durable", "last", "longevity"]
    },
    "Digital_Ebook_Purchase": {
        "plot": ["plot", "story", "narrative"],
        "writing style": ["writing", "style", "prose"],
        "genre": ["genre", "category", "type"]
    },
    "Digital_Music_Purchase": {
        "sound quality": ["sound", "audio", "clarity"],
        "genre": ["genre", "category", "type"],
        "production": ["production", "mixing", "mastering"]
    },
    "Digital_Software": {
        "usability": ["usable", "interface", "navigation"],
        "performance": ["performance", "speed", "efficiency"],
        "features": ["feature", "functionality", "capability"]
    },
    "Digital_Video_Download": {
        "video quality": ["video", "picture", "resolution"],
        "storyline": ["story", "plot", "narrative"],
        "acting": ["acting", "performance", "cast"]
    },
    "Digital_Video_Games": {
        "gameplay": ["gameplay", "mechanics", "controls"],
        "graphics": ["graphics", "visuals", "design"],
        "story": ["story", "plot", "narrative"]
    },
    "Furniture": {
        "comfort": ["comfort", "comfortable", "cozy"],
        "design": ["design", "style", "aesthetic"],
        "durability": ["durable", "last", "longevity"]
    },
    "Gift_Card": {
        "design": ["design", "look", "appearance"],
        "usability": ["usable", "easy", "convenient"],
        "value": ["value", "worth", "price"]
    },
    "Grocery": {
        "taste": ["taste", "flavor", "delicious"],
        "freshness": ["fresh", "freshness", "ripe"],
        "packaging": ["packaging", "package", "container"]
    },
    "Health_Personal_Care": {
        "effectiveness": ["effective", "works", "results"],
        "comfort": ["comfort", "comfortable", "ease"],
        "scent": ["scent", "smell", "fragrance"]
    },
    "Major_Appliances": {
        "performance": ["performance", "efficiency", "function"],
        "durability": ["durable", "last", "longevity"],
        "energy efficiency": ["energy", "efficient", "power"]
    },
    "Mobile_Apps": {
        "usability": ["usable", "interface", "navigation"],
        "performance": ["performance", "speed", "efficiency"],
        "features": ["feature", "functionality", "capability"]
    },
    "Mobile_Electronics": {
        "battery life": ["battery", "battery life", "power"],
        "performance": ["performance", "speed", "efficiency"],
        "design": ["design", "look", "appearance"]
    },
    "Music": {
        "sound quality": ["sound", "audio", "clarity"],
        "genre": ["genre", "category", "type"],
        "production": ["production", "mixing", "mastering"]
    },
    "Musical_Instruments": {
        "sound quality": ["sound", "tone", "acoustics"],
        "durability": ["durable", "last", "longevity"],
        "playability": ["playable", "easy", "comfortable"]
    },
    "Office_Products": {
        "functionality": ["functional", "works", "performance"],
        "durability": ["durable", "last", "longevity"],
        "ease of use": ["easy", "user-friendly", "intuitive"]
    },
    "Outdoors": {
        "durability": ["durable", "last", "longevity"],
        "comfort": ["comfort", "comfortable", "ease"],
        "functionality": ["functional", "works", "performance"]
    },
    "PC": {
        "performance": ["performance", "speed", "efficiency"],
        "graphics": ["graphics", "visuals", "display"],
        "usability": ["usable", "interface", "navigation"]
    },
    "Personal_Care_Appliances": {
        "effectiveness": ["effective", "works", "results"],
        "ease of use": ["easy", "user-friendly", "intuitive"],
        "durability": ["durable", "last", "longevity"]
    },
    "Pet_Products": {
        "durability": ["durable", "last", "longevity"],
        "comfort": ["comfort", "comfortable", "cozy"],
        "safety": ["safe", "safety", "secure"]
    },
    "Shoes": {
        "comfort": ["comfort", "comfortable", "cozy"],
        "fit": ["fit", "size", "fitting"],
        "style": ["style", "design", "look"]
    },
    "Software": {
        "usability": ["usable", "interface", "navigation"],
        "performance": ["performance", "speed", "efficiency"],
        "features": ["feature", "functionality", "capability"]
    },
    "Sports": {
        "durability": ["durable", "last", "longevity"],
        "comfort": ["comfort", "comfortable", "ease"],
        "performance": ["performance", "function", "works"]
    },
    "Tools": {
        "durability": ["durable", "last", "longevity"],
        "ease of use": ["easy", "user-friendly", "intuitive"],
        "effectiveness": ["effective", "works", "results"]
    },
    "Toys": {
        "durability": ["durable", "last", "longevity"],
        "fun": ["fun", "enjoyable", "entertaining"],
        "safety": ["safe", "safety", "secure"]
    },
    "Video_DVD": {
        "video quality": ["video", "picture", "resolution"],
        "storyline": ["story", "plot", "narrative"],
        "acting": ["acting", "performance", "cast"]
    },
    "Video_Games": {
        "gameplay": ["gameplay", "mechanics", "controls"],
        "graphics": ["graphics", "visuals", "design"],
        "story": ["story", "plot", "narrative"]
    },
    "Video": {
        "video quality": ["video", "picture", "resolution"],
        "storyline": ["story", "plot", "narrative"],
        "acting": ["acting", "performance", "cast"]
    },
    "Watches": {
        "design": ["design", "look", "appearance"],
        "durability": ["durable", "last", "longevity"],
        "functionality": ["functional", "works", "features"]
    },
    "Wireless": {
        "signal strength": ["signal", "reception", "connectivity"],
        "battery life": ["battery", "battery life", "power"],
        "ease of use": ["easy", "user-friendly", "intuitive"]
    },
    "Multilingual_US": {
        "quality": ["quality", "standard", "excellence"],
        "usability": ["usable", "interface", "navigation"],
        "features": ["feature", "functionality", "capability"]
    }

}


sample_datasets = {
    "Books": "preprocessed_amazon_reviews_us_Books_v1_02.tsv",
    "Apparel": "preprocessed_amazon_reviews_us_Apparel_v1_00.tsv",
    "Electronics": "preprocessed_amazon_reviews_us_Electronics_v1_00.tsv",
    "Automotive": "preprocessed_amazon_reviews_us_Automotive_v1_00.tsv",
    "Baby": "preprocessed_amazon_reviews_us_Baby_v1_00.tsv",
    "Beauty": "preprocessed_amazon_reviews_us_Beauty_v1_00.tsv",
    "Camera": "preprocessed_amazon_reviews_us_Camera_v1_00.tsv",
    "Digital_Ebook_Purchase": "preprocessed_amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv",
    "Digital_Music_Purchase": "preprocessed_amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv",
    "Digital_Software": "preprocessed_amazon_reviews_us_Digital_Software_v1_00.tsv",
    "Digital_Video_Download": "preprocessed_amazon_reviews_us_Digital_Video_Download_v1_00.tsv",
    "Digital_Video_Games": "preprocessed_amazon_reviews_us_Digital_Video_Games_v1_00.tsv",
    "Furniture": "preprocessed_amazon_reviews_us_Furniture_v1_00.tsv",
    "Gift_Card": "preprocessed_amazon_reviews_us_Gift_Card_v1_00.tsv",
    "Grocery": "preprocessed_amazon_reviews_us_Grocery_v1_00.tsv",
    "Health_Personal_Care": "preprocessed_amazon_reviews_us_Health_Personal_Care_v1_00.tsv",
    "Major_Appliances": "preprocessed_amazon_reviews_us_Major_Appliances_v1_00.tsv",
    "Mobile_Apps": "preprocessed_amazon_reviews_us_Mobile_Apps_v1_00.tsv",
    "Mobile_Electronics": "preprocessed_amazon_reviews_us_Mobile_Electronics_v1_00.tsv",
    "Music": "preprocessed_amazon_reviews_us_Music_v1_00.tsv",
    "Musical_Instruments": "preprocessed_amazon_reviews_us_Musical_Instruments_v1_00.tsv",
    "Office_Products": "preprocessed_amazon_reviews_us_Office_Products_v1_00.tsv",
    "Outdoors": "preprocessed_amazon_reviews_us_Outdoors_v1_00.tsv",
    "PC": "preprocessed_amazon_reviews_us_PC_v1_00.tsv",
    "Personal_Care_Appliances": "preprocessed_amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv",
    "Pet_Products": "preprocessed_amazon_reviews_us_Pet_Products_v1_00.tsv",
    "Shoes": "preprocessed_amazon_reviews_us_Shoes_v1_00.tsv",
    "Software": "preprocessed_amazon_reviews_us_Software_v1_00.tsv",
    "Sports": "preprocessed_amazon_reviews_us_Sports_v1_00.tsv",
    "Tools": "preprocessed_amazon_reviews_us_Tools_v1_00.tsv",
    "Toys": "preprocessed_amazon_reviews_us_Toys_v1_00.tsv",
    "Video_DVD": "preprocessed_amazon_reviews_us_Video_DVD_v1_00.tsv",
    "Video_Games": "preprocessed_amazon_reviews_us_Video_Games_v1_00.tsv",
    "Video": "preprocessed_amazon_reviews_us_Video_v1_00.tsv",
    "Watches": "preprocessed_amazon_reviews_us_Watches_v1_00.tsv",
    "Wireless": "preprocessed_amazon_reviews_us_Wireless_v1_00.tsv",
    "Multilingual_US": "amazon_reviews_multilingual_US_v1_00.tsv"
}



lemmatized_attributes = {}
for category, attributes in category_attributes.items():
    lemmatized_attributes[category] = {}
    for attr, keywords in attributes.items():
        lemmatized_keywords = set()
        for keyword in keywords:
            doc = nlp(keyword)
            for token in doc:
                lemmatized_keywords.add(token.lemma_.lower())
        lemmatized_attributes[category][attr] = lemmatized_keywords

class SentimentClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim1=256, hidden_dim2=128):
        super(SentimentClassifier, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim1)
        self.relu1 = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden_dim2, 2)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu2(x)
        x = self.fc3(x)
        return x

class ReviewDataset(Dataset):
    def __init__(self, texts, labels, vectorizer):
        self.texts = texts
        self.labels = labels
        self.vectorizer = vectorizer
        self.X = self.vectorizer.transform(self.texts).toarray()

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

def preprocess_text(text, nlp):
    doc = nlp(text.lower())
    return " ".join(token.lemma_ for token in doc if not token.is_stop and not token.is_punct)
def train_classifier(df, nlp, sample_size=1000, batch_size=32, epochs=10):
    sample_df = df.sample(min(sample_size, len(df)), random_state=42)
    texts = []
    labels = []
    for _, row in sample_df.iterrows():
        review = str(row['review_body'])
        star_rating = row['star_rating']
        if star_rating in [1, 2]:
            labels.append(0)
        elif star_rating in [4, 5]:
            labels.append(1)
        else:
            continue
        texts.append(preprocess_text(review, nlp))

    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
    X = vectorizer.fit_transform(texts)

    dataset = ReviewDataset(texts, labels, vectorizer)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    model = SentimentClassifier(input_dim=X.shape[1]).to(device)
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)

    neg_count = sum(1 for l in labels if l == 0)
    pos_count = sum(1 for l in labels if l == 1)
    class_weights = torch.tensor([1.0, neg_count/pos_count] if pos_count > 0 else [1.0, 1.0]).to(device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for batch_X, batch_y in dataloader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}")

    return vectorizer, model

def classify_sentence(sentence, vectorizer, model, nlp):
    model.eval()
    preprocessed = preprocess_text(sentence, nlp)
    X = vectorizer.transform([preprocessed]).toarray()
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
    with torch.no_grad():
        output = model(X_tensor)
        probabilities = torch.softmax(output, dim=1)
        label = torch.argmax(probabilities, dim=1).cpu().numpy()[0]
    return "positive" if label == 1 else "negative"

def extract_attribute_sentences(text, lemmatized_attributes, nlp):
    sentences = re.split(r'[.!?]', text)
    attribute_sentences = {attr: [] for attr in lemmatized_attributes}
    for sentence in sentences:
        sentence_lower = sentence.lower().strip()
        if sentence_lower:
            doc = nlp(sentence_lower)
            lemmas = {token.lemma_ for token in doc}
            for attr, lemmatized_keywords in lemmatized_attributes.items():
                if lemmas & lemmatized_keywords:
                    attribute_sentences[attr].append(sentence.strip())
    return attribute_sentences

def process_review(review, attributes, lemmatized_attributes, vectorizer, model, nlp):
    attribute_sentences = extract_attribute_sentences(review, lemmatized_attributes, nlp)
    attribute_sentiments = {}
    for attr, sentences in attribute_sentences.items():
        if sentences:
            sentiments = [classify_sentence(s, vectorizer, model, nlp) for s in sentences]
            positive_count = sum(1 for s in sentiments if s == 'positive')
            negative_count = sum(1 for s in sentiments if s == 'negative')
            if positive_count > negative_count:
                sentiment_label = "positive"
            elif negative_count > positive_count:
                sentiment_label = "negative"
            else:
                sentiment_label = "neutral"
            attribute_sentiments[attr] = f"The {attr} is {sentiment_label}."
        else:
            attribute_sentiments[attr] = "No mention."
    return attribute_sentiments

def process_product(group, category, lemmatized_attributes, vectorizer, model, nlp):
    attributes = category_attributes.get(category, {})
    combined_reviews = " ".join(str(review) for review in group['review_body'] if pd.notna(review))
    attribute_sentences = extract_attribute_sentences(combined_reviews, lemmatized_attributes[category], nlp)
    attribute_summaries = {}
    for attr, sentences in attribute_sentences.items():
        if sentences:
            sentiments = [classify_sentence(s, vectorizer, model, nlp) for s in sentences]
            positive_count = sum(1 for s in sentiments if s == 'positive')
            negative_count = sum(1 for s in sentiments if s == 'negative')
            total = positive_count + negative_count
            if total > 0:
                positive_percentage = (positive_count / total) * 100
            else:
                positive_percentage = 0
            attribute_summaries[attr] = (positive_percentage, positive_count, negative_count)
        else:
            attribute_summaries[attr] = (None, 0, 0)
    sample_review = None
    for review in group['review_body']:
        if pd.notna(review):
            review_sentences = extract_attribute_sentences(str(review), lemmatized_attributes[category], nlp)
            if any(review_sentences[attr] for attr in review_sentences):
                sample_review = review
                break
    if sample_review is None:
        sample_review = group['review_body'].iloc[0]
    sample_review_sentiments = process_review(sample_review, attributes, lemmatized_attributes[category], vectorizer, model, nlp)
    output = []
    output.append(f"Sample Review: {sample_review[:100]}...")
    for attr, sentiment in sample_review_sentiments.items():
        output.append(f"{attr.capitalize()}: {sentiment}")
    output.append(f"Product ID: {group['product_id'].iloc[0]}")
    output.append("Product-Level Sentiments:")
    for attr in attributes:
        if attribute_summaries[attr][0] is not None:
            output.append(f"  {attr.capitalize()}: {attribute_summaries[attr][0]:.2f}% positive mentions ({attribute_summaries[attr][1]} positive, {attribute_summaries[attr][2]} negative)")
        else:
            output.append(f"  {attr.capitalize()}: No mentions in the reviews")
    return "\n".join(output), attribute_summaries

def evaluate_classifier(df, vectorizer, model, nlp, sample_size=1000):
    model.eval()
    sample_df = df.sample(min(sample_size, len(df)), random_state=42)
    texts = []
    true_labels = []
    pred_labels = []
    pred_probs = []
    for _, row in sample_df.iterrows():
        review = str(row['review_body'])
        star_rating = row['star_rating']
        if star_rating in [1, 2]:
            true_labels.append(0)
        elif star_rating in [4, 5]:
            true_labels.append(1)
        else:
            continue
        preprocessed = preprocess_text(review, nlp)
        X = vectorizer.transform([preprocessed]).toarray()
        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
        with torch.no_grad():
            output = model(X_tensor)
            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]
            label = np.argmax(probabilities)
            pred_probs.append(probabilities[1])
        pred_labels.append(label)
        texts.append(preprocessed)
    if not true_labels:
        return {}, [], [], []
    metrics = {
        'accuracy': accuracy_score(true_labels, pred_labels),
        'precision': precision_score(true_labels, pred_labels, zero_division=0),
        'recall': recall_score(true_labels, pred_labels, zero_division=0),
        'f1': f1_score(true_labels, pred_labels, zero_division=0),
        'roc_auc': roc_auc_score(true_labels, pred_probs) if pred_probs else 0.0,
        'confusion_matrix': confusion_matrix(true_labels, pred_labels, labels=[0, 1])
    }
    return metrics, true_labels, pred_labels, pred_probs

all_summaries = []
category_metrics = {}
category_evaluation = {}
all_true_labels = []
all_pred_labels = []
all_pred_probs = []

for category, file in sample_datasets.items():
    print(f"Processing {category} dataset: {file}")
    try:
        df = pd.read_csv(file, sep='\t', usecols=["product_id", "review_body", "star_rating"])
    except FileNotFoundError:
        print(f"File not found: {file}")
        continue
    vectorizer, model = train_classifier(df, nlp)
    metrics, true_labels, pred_labels, pred_probs = evaluate_classifier(df, vectorizer, model, nlp)
    category_evaluation[category] = metrics
    all_true_labels.extend(true_labels)
    all_pred_labels.extend(pred_labels)
    all_pred_probs.extend(pred_probs)
    grouped = df.groupby('product_id')
    category_metrics[category] = {attr: [] for attr in category_attributes.get(category, {})}
    for product_id, group in grouped:
        output, attribute_summaries = process_product(group, category, lemmatized_attributes, vectorizer, model, nlp)
        print(output)
        all_summaries.append(output)
        for attr, (percentage, _, _) in attribute_summaries.items():
            if percentage is not None:
                category_metrics[category][attr].append(percentage)

average_metrics = {}
for category, attributes in category_metrics.items():
    average_metrics[category] = {}
    for attr, percentages in attributes.items():
        if percentages:
            average_metrics[category][attr] = sum(percentages) / len(percentages)
        else:
            average_metrics[category][attr] = 0

for category in average_metrics:
    plt.figure(figsize=(10, 6))
    plt.bar(average_metrics[category].keys(), average_metrics[category].values(), color='skyblue')
    plt.title(f"Average Positive Mention Percentage for {category}")
    plt.xlabel("Attributes")
    plt.ylabel("Average Positive Percentage (%)")
    plt.ylim(0, 100)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(f"{category}_positive_percentage.png")
    plt.close()

if all_true_labels:
    aggregated_cm = confusion_matrix(all_true_labels, all_pred_labels, labels=[0, 1])
    aggregated_accuracy = accuracy_score(all_true_labels, all_pred_labels)
    aggregated_f1 = f1_score(all_true_labels, all_pred_labels, zero_division=0)
    total = aggregated_cm.sum()
    percentages = (aggregated_cm / total * 100).round(2)
    annotations = np.array([[f"{int(count)}\n({pct}%)" for count, pct in zip(row, prow)]
                           for row, prow in zip(aggregated_cm, percentages)])

    plt.figure(figsize=(10, 8))
    sns.heatmap(aggregated_cm, annot=annotations, fmt='', cmap='YlOrRd',
                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'],
                cbar_kws={'label': 'Count'})
    plt.title(f"Aggregated Confusion Matrix\nAccuracy: {aggregated_accuracy:.2f}, F1 Score: {aggregated_f1:.2f}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.savefig("all_categories_confusion_matrix.png")
    plt.close()

    normalized_cm = confusion_matrix(all_true_labels, all_pred_labels, labels=[0, 1], normalize='true').round(4) * 100
    plt.figure(figsize=(10, 8))
    sns.heatmap(normalized_cm, annot=True, fmt='.2f', cmap='YlOrRd',
                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'],
                cbar_kws={'label': 'Percentage (%)'})
    plt.title(f"Normalized Aggregated Confusion Matrix\nAccuracy: {aggregated_accuracy:.2f}, F1 Score: {aggregated_f1:.2f}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.savefig("all_categories_normalized_confusion_matrix.png")
    plt.close()

with open("product_summaries.txt", "w") as f:
    f.write("\n\n".join(all_summaries))

with open("category_metrics.txt", "w") as f:
    for category in average_metrics:
        f.write(f"\n{category}:\n")
        f.write("Average Positive Mention Percentages:\n")
        for attr, avg in average_metrics[category].items():
            f.write(f"  {attr.capitalize()}: {avg:.2f}% average positive mentions\n")
        if category in category_evaluation:
            f.write("Classification Metrics:\n")
            metrics = category_evaluation[category]
            if metrics:
                f.write(f"  Accuracy: {metrics['accuracy']:.2f}\n")
                f.write(f"  Precision: {metrics['precision']:.2f}\n")
                f.write(f"  Recall: {metrics['recall']:.2f}\n")
                f.write(f"  F1 Score: {metrics['f1']:.2f}\n")
                f.write(f"  ROC-AUC: {metrics['roc_auc']:.2f}\n")

print("Processing complete. Summaries saved to product_summaries.txt, metrics to category_metrics.txt, and visualizations as PNG files.")